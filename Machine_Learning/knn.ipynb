{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAfFPP1_4TYQ",
        "outputId": "463f8012-dcd8-4756-f3a7-aa27a0ab542b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define Gabor filter parameters\n",
        "orientations = 8\n",
        "frequencies = [0.1, 0.5, 1.0]\n",
        "kernel_size = 21  # Adjust this based on your image size and requirements\n",
        "\n",
        "# Specify the folder containing your images\n",
        "image_folder = '/content/sample_data/dataset'\n",
        "\n",
        "# Create an output folder to save the preprocessed images\n",
        "output_folder = '/content/sample_data/preprocessed'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Initialize the Gabor filter bank\n",
        "gabor_filters = []\n",
        "\n",
        "# Create the Gabor filters\n",
        "for theta in range(orientations):\n",
        "    for freq in frequencies:\n",
        "        kernel = cv2.getGaborKernel(\n",
        "            (kernel_size, kernel_size),\n",
        "            sigma=4.0,  # Adjust the sigma value as needed\n",
        "            theta=theta * (np.pi / orientations),\n",
        "            lambd=10.0 / freq,\n",
        "            gamma=0.5,\n",
        "            psi=0,\n",
        "        )\n",
        "        gabor_filters.append(kernel)\n",
        "\n",
        "# Process each image in the folder\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Filter for image file extensions\n",
        "        # Load the image\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Initialize an empty list to store the filtered images\n",
        "        filtered_images = []\n",
        "\n",
        "        # Apply the Gabor filters to the image\n",
        "        for kernel in gabor_filters:\n",
        "            filtered_image = cv2.filter2D(image, cv2.CV_64F, kernel)\n",
        "            filtered_images.append(filtered_image)\n",
        "\n",
        "        # Save the preprocessed images to the output folder\n",
        "        output_filename = os.path.splitext(filename)[0] + '_preprocessed.jpg'\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "        preprocessed_image = np.hstack(filtered_images)  # Combine filtered images side by side\n",
        "        cv2.imwrite(output_path, preprocessed_image)\n",
        "\n",
        "print(\"Preprocessing complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9aL6z4KHFI6"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v570F-gfISo7"
      },
      "outputs": [],
      "source": [
        "with ZipFile('/content/MICC-F220.zip','r') as z:\n",
        "  z.extractall(\"/content/sample_data/dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl14gO57HnZK",
        "outputId": "4c87e021-9524-4da3-8107-3514ba5ddafb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting zipfile36\n",
            "  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install zipfile36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xvb1quo9DXf",
        "outputId": "bbbc310e-0220-43ec-b09d-3638d195cfa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LBP feature extraction complete.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from skimage import feature\n",
        "\n",
        "# Specify the folder containing your preprocessed images\n",
        "preprocessed_folder = '/content/sample_data/preprocessed'\n",
        "\n",
        "# Create an output folder to save the LBP feature vectors\n",
        "lbp_output_folder = '/content/sample_data/features'\n",
        "os.makedirs(lbp_output_folder, exist_ok=True)\n",
        "\n",
        "# LBP parameters\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "\n",
        "# Process each preprocessed image\n",
        "for filename in os.listdir(preprocessed_folder):\n",
        "    if filename.endswith(('_preprocessed.jpg')):  # Filter for preprocessed images\n",
        "        # Load the preprocessed image\n",
        "        image_path = os.path.join(preprocessed_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Compute LBP features\n",
        "        lbp_image = feature.local_binary_pattern(image, n_points, radius, method='uniform')\n",
        "\n",
        "        # Flatten the LBP image into a feature vector\n",
        "        lbp_feature_vector, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
        "\n",
        "        # Save the LBP feature vector as a CSV file or any other format you prefer\n",
        "        output_filename = os.path.splitext(filename)[0] + '_lbp.csv'\n",
        "        output_path = os.path.join(lbp_output_folder, output_filename)\n",
        "        np.savetxt(output_path, lbp_feature_vector, delimiter=',')\n",
        "\n",
        "print(\"LBP feature extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50_o7HuzfyJ4",
        "outputId": "7c369a89-8b9c-450c-bf5b-c49e5fb1d771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 47.73%\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CRW       0.57      1.00      0.73         8\n",
            "          DSC       0.90      0.60      0.72        15\n",
            "       DSCF10       0.00      0.00      0.00         0\n",
            "       DSCF13       0.00      0.00      0.00         1\n",
            "       DSCF15       0.00      0.00      0.00         0\n",
            "        DSCF2       0.00      0.00      0.00         1\n",
            "     DSCF2059       0.00      0.00      0.00         0\n",
            "   DSCF8tamp1       0.00      0.00      0.00         0\n",
            " DSCF8tamp132       0.00      0.00      0.00         1\n",
            " DSCF8tamp133       0.00      0.00      0.00         0\n",
            " DSCF8tamp237       0.00      0.00      0.00         1\n",
            "  DSCF8tamp25       0.00      0.00      0.00         1\n",
            "        DSCF9       0.00      0.00      0.00         1\n",
            "     DSCN2322       0.00      0.00      0.00         0\n",
            "     DSCN2329       0.00      0.00      0.00         1\n",
            "       DSCN41       0.00      0.00      0.00         0\n",
            "  DSCN41tamp1       0.00      0.00      0.00         0\n",
            "DSCN41tamp131       0.00      0.00      0.00         1\n",
            "DSCN41tamp132       0.00      0.00      0.00         1\n",
            "       DSCN45       0.00      0.00      0.00         1\n",
            "  DSCN45tamp1       0.00      0.00      0.00         1\n",
            "DSCN45tamp131       0.00      0.00      0.00         0\n",
            "DSCN45tamp132       0.00      0.00      0.00         1\n",
            "DSCN45tamp237       0.00      0.00      0.00         1\n",
            "     P1000528       0.00      0.00      0.00         1\n",
            "         sony       1.00      0.57      0.73         7\n",
            "\n",
            "     accuracy                           0.48        44\n",
            "    macro avg       0.10      0.08      0.08        44\n",
            " weighted avg       0.57      0.48      0.49        44\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Load LBP features and labels\n",
        "lbp_feature_folder = '/content/sample_data/features'\n",
        "labels = []  # Store class labels\n",
        "feature_vectors = []  # Store LBP feature vectors\n",
        "\n",
        "# Iterate through the LBP feature files\n",
        "for filename in os.listdir(lbp_feature_folder):\n",
        "    if filename.endswith('_lbp.csv'):\n",
        "        # Extract class label from the filename\n",
        "        class_label = filename.split('_')[0]\n",
        "\n",
        "        # Load LBP feature vector\n",
        "        feature_vector = np.loadtxt(os.path.join(lbp_feature_folder, filename), delimiter=',')\n",
        "\n",
        "        labels.append(class_label)\n",
        "        feature_vectors.append(feature_vector)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check if there are classes with very few samples\n",
        "class_counts = Counter(y_train)\n",
        "min_class_count = min(class_counts.values())\n",
        "\n",
        "# Apply SMOTE only if the minimum class count is greater than 1\n",
        "if min_class_count > 1:\n",
        "    # Apply SMOTE to handle imbalanced classes\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "else:\n",
        "    # Use the original data without SMOTE\n",
        "    X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "    X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "    y_train_resampled = y_train\n",
        "\n",
        "# Initialize and train a K-Nearest Neighbors (KNN) classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (K) as needed\n",
        "knn_classifier.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Predict the labels for the scaled test data\n",
        "y_pred = knn_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY-Sz1Z3fHDj",
        "outputId": "c4dc3fdf-0ee4-44af-cf53-98c26d1aa07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 56.82%\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CRW       0.80      1.00      0.89         8\n",
            "          DSC       0.93      0.87      0.90        15\n",
            "       DSCF10       0.00      0.00      0.00         0\n",
            "       DSCF13       0.00      0.00      0.00         1\n",
            "        DSCF2       0.00      0.00      0.00         1\n",
            "        DSCF6       0.00      0.00      0.00         0\n",
            "   DSCF8tamp1       0.00      0.00      0.00         0\n",
            " DSCF8tamp132       0.00      0.00      0.00         1\n",
            " DSCF8tamp237       0.00      0.00      0.00         1\n",
            "  DSCF8tamp25       0.00      0.00      0.00         1\n",
            "  DSCF8tamp27       0.00      0.00      0.00         0\n",
            "  DSCF8tamp37       0.00      0.00      0.00         0\n",
            "        DSCF9       0.00      0.00      0.00         1\n",
            "     DSCN2329       0.00      0.00      0.00         1\n",
            "       DSCN41       0.00      0.00      0.00         0\n",
            "DSCN41tamp131       0.00      0.00      0.00         1\n",
            "DSCN41tamp132       0.00      0.00      0.00         1\n",
            "       DSCN43       0.00      0.00      0.00         0\n",
            "       DSCN45       0.00      0.00      0.00         1\n",
            "  DSCN45tamp1       0.00      0.00      0.00         1\n",
            "DSCN45tamp132       0.00      0.00      0.00         1\n",
            "DSCN45tamp134       0.00      0.00      0.00         0\n",
            "DSCN45tamp237       0.00      0.00      0.00         1\n",
            " DSCN45tamp27       0.00      0.00      0.00         0\n",
            "       DSCN48       0.00      0.00      0.00         0\n",
            "     P1000528       0.00      0.00      0.00         1\n",
            "         sony       0.67      0.57      0.62         7\n",
            "\n",
            "     accuracy                           0.57        44\n",
            "    macro avg       0.09      0.09      0.09        44\n",
            " weighted avg       0.57      0.57      0.57        44\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Load LBP features and labels\n",
        "lbp_feature_folder = '/content/sample_data/features'\n",
        "labels = []  # Store class labels\n",
        "feature_vectors = []  # Store LBP feature vectors\n",
        "\n",
        "# Iterate through the LBP feature files\n",
        "for filename in os.listdir(lbp_feature_folder):\n",
        "    if filename.endswith('_lbp.csv'):\n",
        "        # Extract class label from the filename\n",
        "        class_label = filename.split('_')[0]\n",
        "\n",
        "        # Load LBP feature vector\n",
        "        feature_vector = np.loadtxt(os.path.join(lbp_feature_folder, filename), delimiter=',')\n",
        "\n",
        "        labels.append(class_label)\n",
        "        feature_vectors.append(feature_vector)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check if there are classes with very few samples\n",
        "class_counts = Counter(y_train)\n",
        "min_class_count = min(class_counts.values())\n",
        "\n",
        "# Apply SMOTE only if the minimum class count is greater than 1\n",
        "if min_class_count > 1:\n",
        "    # Apply SMOTE to handle imbalanced classes\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "else:\n",
        "    # Use the original data without SMOTE\n",
        "    X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "    X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "    y_train_resampled = y_train\n",
        "\n",
        "# Initialize and train a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Predict the labels for the scaled test data\n",
        "y_pred = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Print classification report for more detailed metrics\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
